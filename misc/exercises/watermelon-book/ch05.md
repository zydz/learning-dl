### 第五章 神经网络

#### 5.1 试述将线性函数$f(x)=w^\top x$用作神经元激活函数的缺陷。

#### 5.2 试述使用图5.2(b)激活函数的神经元与对率回归的联系。

#### 5.3 对于图5.7中的$v_{ih}$,试推导出BP算法中的更新公式(5.13)。

#### 5.4 试述式(5.6)中学习率的取值对神经网络训练的影响。

#### 5.5 试编程实现标准BP算法和累计BP算法，在西瓜数据集3.0上分别用这两个算法训练一个单隐层网络，并进行比较。

#### 5.6 试设计一个BP改进算法，能通过动态调整学习率显著提升收敛速度。编程实现该算法，并选择两个UCI数据集与标准BP算法进行实验比较。

#### 5.7 根据式（5.18）和（5.19），试构造一个能解决异或问题的单层RBP神经网络。

#### 5.8 从网上下载或自己编程实现SOM网络，并观察其在西瓜数据集$3.0\alpha$上产生的结果。

#### 5.9* 试推导用于Elman网络的BP算法。

#### 从网上下载或自己编程实现一个卷积神经网络，并在手写字符识别数据MNIST上进行实验测试。
